library(corrplot)
library("lm.beta")
tree<-rpart(CHURN ~ ., data=df, method="class",cp=0.0005)
prp(tree)
rpart.plot(tree,digits=-2)
plotcp(tree)
tree_cp036 = rpart(CHURN ~ .,df, method="class",cp= 0.036 )
rpart.plot(tree_cp036 ,digits=-2)
plotcp(tree_cp036)
#| echo: true
#| message: true
predict(tree, newdata=df)
confusionMatrix()
#| echo: true
#| message: true
predict <- predict(tree_cp036, newdata=df,  type="response")
#| echo: true
#| message: true
df_pred <- df
df_pred$pred = predict(tree_cp036, newdata = df, type="class")
confusionMatrix(df_pred$pred,as.factor(df_pred$CHURN), positive="1")
#| echo: true
#| message: true
predict_tree_cp036 <- predict(tree_cp036, newdata=df,  type="response")
rm(list = ls())
#Loading some neccesary libraries
#Add any missing ones as you need them!
library(tidyverse)
df<-read.csv("driverschurn.csv")
str(df)
summary(df)
unique(df$STATUS)
table(df$STATUS)
unique(df$GENDER)
table(df$GENDER)
unique(df$CHILDREN)
table(df$CHILDREN)
set.seed(1013, sample.kind = "Rejection")
#split the dataset leaving 80% of observations in the training dataset and 20% in the test dataset:
spl = sample(nrow(df),0.8*nrow(df))
head(spl)
# Now lets split our dataset into train and test:
train.df = df[spl,]
test.df = df[-spl,]
m1<-lm(CHURN~ACTSAL,data=train.df)
summary(m1)
m2<-lm(CHURN~ACTSAL+EXPSAL,data=train.df)
summary(m2)
m3<-lm(CHURN~.,data=train.df)
summary(m3)
#| echo: true
#| message: true
#|
library(jtools)
library(sjPlot)
# Generate the table using tab_model()
#transform
model_table <- tab_model(m1, m2, m3,dv.labels = c("(1):", "(2)","(3)"),show.ci=FALSE,collapse.se=TRUE, p.threshold = c(0.1, 0.05, 0.01,0.001),p.style = "stars",
string.se = "std. Error",
string.p = "p-value",transform=NULL,digits=6)
# Print the table
model_table
#| echo: true
#| message: true
#|
library(rpart)
library(rpart.plot)
tree<-rpart(CHURN ~ ., data=train.df, method="anova")
rpart.plot(tree,digits=-2)
#| echo: true
#| message: true
library(rpart)
library(rpart.plot)
library(tidyverse)
library(caTools)
library(ROCR)
library(caret)
library(corrplot)
library("lm.beta")
tree<-rpart(CHURN ~ ., data=df, method="class",cp=0.0005)
prp(tree)
rpart.plot(tree,digits=-2)
plotcp(tree)
tree_cp036 = rpart(CHURN ~ .,df, method="class",cp= 0.036 )
rpart.plot(tree_cp036 ,digits=-2)
plotcp(tree_cp036)
#| echo: true
#| message: true
df_pred <- df
df_pred$pred = predict(tree_cp036, newdata = df, type="class")
confusionMatrix(df_pred$pred,as.factor(df_pred$CHURN), positive="1")
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
rm(list = ls())
#Loading some neccesary libraries
#Add any missing ones as you need them!
library(tidyverse)
df<-read.csv("driverschurn.csv")
str(df)
summary(df)
unique(df$STATUS)
table(df$STATUS)
unique(df$GENDER)
table(df$GENDER)
unique(df$CHILDREN)
table(df$CHILDREN)
set.seed(1013, sample.kind = "Rejection")
#split the dataset leaving 80% of observations in the training dataset and 20% in the test dataset:
spl = sample(nrow(df),0.8*nrow(df))
head(spl)
# Now lets split our dataset into train and test:
train.df = df[spl,]
test.df = df[-spl,]
m1<-lm(CHURN~ACTSAL,data=train.df)
summary(m1)
m2<-lm(CHURN~ACTSAL+EXPSAL,data=train.df)
summary(m2)
m3<-lm(CHURN~.,data=train.df)
summary(m3)
#| echo: true
#| message: true
#|
library(jtools)
library(sjPlot)
# Generate the table using tab_model()
#transform
model_table <- tab_model(m1, m2, m3,dv.labels = c("(1):", "(2)","(3)"),show.ci=FALSE,collapse.se=TRUE, p.threshold = c(0.1, 0.05, 0.01,0.001),p.style = "stars",
string.se = "std. Error",
string.p = "p-value",transform=NULL,digits=6)
# Print the table
model_table
#| echo: true
#| message: true
#|
library(rpart)
library(rpart.plot)
tree<-rpart(CHURN ~ ., data=train.df, method="anova")
rpart.plot(tree,digits=-2)
#| echo: true
#| message: true
library(rpart)
library(rpart.plot)
library(tidyverse)
library(caTools)
library(ROCR)
library(caret)
library(corrplot)
library("lm.beta")
tree<-rpart(CHURN ~ ., data=df, method="class",cp=0.0005)
prp(tree)
rpart.plot(tree,digits=-2)
plotcp(tree)
tree_cp036 = rpart(CHURN ~ .,df, method="class",cp= 0.036 )
rpart.plot(tree_cp036 ,digits=-2)
plotcp(tree_cp036)
#| echo: true
#| message: true
df_pred <- df
df_pred$pred = predict(tree_cp036, newdata = df, type="class")
confusionMatrix(df_pred$pred,as.factor(df_pred$CHURN), positive="1")
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred = predict(logreg, newdata = df, type="class")
View(m1)
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
conmat <- confusionMatrix(df_logreg$pred,as.factor(df_logreg$CHURN), positive="1")
df_logreg$pred
df_logreg$CHURN
df_logreg$pred
df_logreg$CHURN
df_logreg$pred
#| echo: true
#| message: true
cutoff <- 0.50
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
reference <- df_logreg$CHURN
data <- df_logreg$pred
all_levels <- union(levels(factor(reference)), levels(factor(data)))
reference <- factor(reference, levels = all_levels)
data <- factor(data, levels = all_levels)
conmat <- caret::confusionMatrix(data, reference, positive="1")
cat(conmat)
#| echo: true
#| message: true
cutoff <- 0.50
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
reference <- df_logreg$CHURN
data <- df_logreg$pred
all_levels <- union(levels(factor(reference)), levels(factor(data)))
reference <- factor(reference, levels = all_levels)
data <- factor(data, levels = all_levels)
conmat <- caret::confusionMatrix(data, reference, positive="1")
## Using Cut Off value for prediction
df_logreg$Churn_predicted <- ifelse(df_logreg$pred >= cutoff,1,0)
cat(paste("For a cutoff point of",
cutoff, "predicted CHURN is",
round(mean(df_logreg$Churn_predicted),2)), "\n\n")
# Calculate the exp(coefficient) for these variables and cut and paste them in the space below.
coeftable <- data.frame(col1=coef(logreg),col2=exp(coef(logreg)))
colnames(coeftable)<-c('Coefficient (log-odds)','e^coefficient (odds)')
coeftable
#| echo: true
#| message: true
cutoff <- 0.50
## Using Cut Off value for prediction
df_logreg$Churn_predicted <- ifelse(df_logreg$pred >= cutoff,1,0)
cat(paste("For a cutoff point of",
cutoff, "predicted CHURN is",
round(mean(df_logreg$Churn_predicted),2)), "\n\n")
# Calculate the exp(coefficient)
coeftable <- data.frame(col1=coef(logreg),col2=exp(coef(logreg)))
colnames(coeftable)<-c('Coefficient (log-odds)','e^coefficient (odds)')
coeftable
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
reference <- df_logreg$CHURN
data <- df_logreg$pred
## Address weird level errors
all_levels <- union(levels(factor(reference)), levels(factor(data)))
reference <- factor(reference, levels = all_levels)
data <- factor(data, levels = all_levels)
conmat <- caret::confusionMatrix(data, reference, positive="1")
print(conmat)
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
summary(df_logreg$pred)
reference <- df_logreg$CHURN
data <- df_logreg$pred
## Address weird level errors
all_levels <- union(levels(factor(reference)), levels(factor(data)))
reference <- factor(reference, levels = all_levels)
data <- factor(data, levels = all_levels)
conmat <- caret::confusionMatrix(data, reference, positive="1")
print(conmat)
#| echo: true
#| message: true
cutoff <- 0.50
## Using Cut Off value for prediction
df_logreg$Churn_predicted <- ifelse(df_logreg$pred >= cutoff,1,0)
cat(paste("For a cutoff point of",
cutoff, "predicted CHURN is",
round(mean(df_logreg$Churn_predicted),2)), "\n\n")
# Calculate the exp(coefficient)
coeftable <- data.frame(col1=coef(logreg),col2=exp(coef(logreg)))
colnames(coeftable)<-c('Coefficient (log-odds)','e^coefficient (odds)')
coeftable
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
rm(list = ls())
#Loading some neccesary libraries
#Add any missing ones as you need them!
library(tidyverse)
df<-read.csv("driverschurn.csv")
str(df)
summary(df)
unique(df$STATUS)
table(df$STATUS)
unique(df$GENDER)
table(df$GENDER)
unique(df$CHILDREN)
table(df$CHILDREN)
set.seed(1013, sample.kind = "Rejection")
#split the dataset leaving 80% of observations in the training dataset and 20% in the test dataset:
spl = sample(nrow(df),0.8*nrow(df))
head(spl)
# Now lets split our dataset into train and test:
train.df = df[spl,]
test.df = df[-spl,]
m1<-lm(CHURN~ACTSAL,data=train.df)
summary(m1)
m2<-lm(CHURN~ACTSAL+EXPSAL,data=train.df)
summary(m2)
m3<-lm(CHURN~.,data=train.df)
summary(m3)
#| echo: true
#| message: true
#|
library(jtools)
library(sjPlot)
# Generate the table using tab_model()
#transform
model_table <- tab_model(m1, m2, m3,dv.labels = c("(1):", "(2)","(3)"),show.ci=FALSE,collapse.se=TRUE, p.threshold = c(0.1, 0.05, 0.01,0.001),p.style = "stars",
string.se = "std. Error",
string.p = "p-value",transform=NULL,digits=6)
# Print the table
model_table
#| echo: true
#| message: true
#|
library(rpart)
library(rpart.plot)
tree<-rpart(CHURN ~ ., data=train.df, method="anova")
rpart.plot(tree,digits=-2)
#| echo: true
#| message: true
library(rpart)
library(rpart.plot)
library(tidyverse)
library(caTools)
library(ROCR)
library(caret)
library(corrplot)
library("lm.beta")
tree<-rpart(CHURN ~ ., data=df, method="class",cp=0.0005)
prp(tree)
rpart.plot(tree,digits=-2)
plotcp(tree)
tree_cp036 = rpart(CHURN ~ .,df, method="class",cp= 0.036 )
rpart.plot(tree_cp036 ,digits=-2)
plotcp(tree_cp036)
#| echo: true
#| message: true
df_pred <- df
df_pred$pred = predict(tree_cp036, newdata = df, type="class")
confusionMatrix(df_pred$pred,as.factor(df_pred$CHURN), positive="1")
#| echo: true
#| message: true
logreg <- glm(CHURN ~ ., data=df, family="binomial")
summary(logreg)
df_logreg <- df
df_logreg$pred <- predict(logreg, newdata = df, type="response")
summary(df_logreg$pred)
reference <- df_logreg$CHURN
data <- df_logreg$pred
conmat <- caret::confusionMatrix( df_logreg$pred ,as.factor(df_logreg$CHURN), positive="1")
#| echo: true
#| message: true
cutoff <- 0.50
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = c("0", "1"))
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = c("0", "1"))
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
reference <- df_logreg$CHURN
data <- df_logreg$pred
conmat <- caret::confusionMatrix( df_logreg$pred ,as.factor(df_logreg$CHURN), positive="1")
#| echo: true
#| message: true
cutoff <- 0.50
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
#| echo: true
#| message: true
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
plot(perf,                      # the data
main = "ROC Curve",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
##
## CONFUSION MATRIX
##
cutoff <- 0.50
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
#| echo: true
#| message: true
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
plot(perf,                      # the data
main = "ROC Curve",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
##
## CONFUSION MATRIX
##
cutoff <- 0.50
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
#| echo: true
#| message: true
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
plot(perf,                      # the data
main = "ROC Curve",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
##
## CONFUSION MATRIX
##
cutoff <- 0.50
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
perf
perf_auc
#| echo: true
#| message: true
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
perf_auc = performance(roc.pred, "auc")
plot(perf,                      # the data
main = "ROC Curve",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
##
## CONFUSION MATRIX
##
cutoff <- 0.50
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
as.numeric(perf_auc@y.values)
#| echo: true
#| message: true
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
plot(perf,                      # the data
main = "ROC Curve for 0.5 Cutoff",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
perf_auc = performance(roc.pred, "auc")
as.numeric(perf_auc@y.values)
##
## CONFUSION MATRIX
##
cutoff <- 0.30
levels <- c("0", "1")
## Using Cut Off value for prediction
# Convert predicted probabilities to predicted classes using a threshold (e.g., 0.5)
df_logreg$pred_class <- factor(ifelse(df_logreg$pred > cutoff, "1", "0"), levels = levels )
# Ensure the reference vector is a factor with the same levels
df_logreg$CHURN <- factor(df_logreg$CHURN, levels = levels )
# create the confusion matrix
conmat <- caret::confusionMatrix(df_logreg$pred_class, df_logreg$CHURN, positive = "1")
conmat
roc.pred = prediction(df_logreg$pred, df_logreg$CHURN)
perf = performance(roc.pred, "tpr", "fpr")
plot(perf,                      # the data
main = "ROC Curve for updated Cutoff",        # the chart's title
xlab = "1 - Specificity",  # the name of the x-axis
ylab = "Sensitivity",      # the name of the y-axis
colorize=TRUE)             # add color to curve depending on threshold prob.
abline(0,1) # adds line at intercept 0, with slope 1
perf_auc = performance(roc.pred, "auc")
as.numeric(perf_auc@y.values)
conmat
length(df)
nrow(df)
