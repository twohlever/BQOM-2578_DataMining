---
title: "Assignment 04 Trees"
subtitle: "BQOM 2578 | Data Mining"
date: "10/19/2025"
date-format: "full"
author: "Theresa Wohlever"
editor: source
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: false
    mainfont: "Georgia"
    sansfont: "Avenir"
    monofont: "Menlo"
    monofontoptions: "Scale=0.6"
    mathfont: "STIX Two Math"
    pdf-engine: xelatex
---
 
# Executive Summary

How well can we predict county Suicide Rates from the hospital information on a per county basis within Pennsylvania? Combine both county Suicide rate data with all PA hospital data to address this question. Dependent Variable is the County Suicide rate.
The Data preparation includes removing a large number of features expected to be unrelated to suicide rates, changing the representation of categorical variables to integers, and joining hospital data and county level suicide data.



Logistic regression provides insight into the impact of included features. Selected features were those shown to demonstrate significant impact on the linear regression. Using these features in a Logistic Regression we can better percieve their impact on County Suicide Rates.

| Feature | Logistic Regression | Regression Tree | Classification Tree|
|:---:|:---:|:---:|:---:| 
|`children_hospital`| Very large effect (β = 2.849) | Not Used | Not Used|
|`psych_over17`| Small effect, but not significant (β = 0.184)   | Not Used | Not Used |
| `discharges1864`| Very small but significant effect (β = 0.0001) | Primary split variable  First split at 2,228  Subsequent splits: 153, 254, 349, 523, 8431, etc.  Most important predictor  OSR² = 0.088, MAE = 48.32 | Primary and only split variable  Main split at 8,431 discharges  Tree 1 accuracy: 72.73%  Trees 2 & 3 accuracy: 77.27% |
| `psych_over17_beds_lic` | Negligible effect (β = 0.001) | Not Used | Not Used |
| `psychiatrists` | x | x | x |
| `clinic_psychiatric`  | x | x | x |
| `comprehensive_rehab` | x | x | x |
|`type_of_organization`| x | x | x |

These findings are discussed in detail in [Logistic Regression Model 2 (Multi-Variable) : Beta Coefficients Discussion](#logistic-model-discussion).


# Data Preparation

```{r}
#| label: LoadPackages
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


rm(list = ls())

# library(caTools)
# library(ROCR)
library(caret)
library(tidyverse)
library("tidyr") #pivot_longer
library(corrplot)
library(tidyverse)
# library("lm.beta")
library(rpart)
library(rpart.plot)

working_directory <- "/Users/theresawohlever/git_repos/BQOM-2578_DataMining/BQOM-2578_DataMining_twohlever/assignments/04-Trees"
setwd(working_directory)

CSV_base_filename <- "hospital extract 2023"
CSV_IN_FILE <- paste(working_directory, "/", "raw_data/", CSV_base_filename, ".csv", sep = "")
CSV_OUT_FILE <- paste(working_directory, "/", CSV_base_filename, "_processed.csv", sep = "")

CSV_S_base_filename <- "SuicideByCounty"
CSV_S_IN_FILE <- paste(working_directory, "/", "raw_data/", CSV_S_base_filename, ".csv", sep = "")
CSV_S_OUT_FILE <- paste(working_directory, "/", CSV_S_base_filename, "_processed.csv", sep = "")

```

## Importing Data, Cleaning, & Wrangling

```{r}
#| label: ImportData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# read.csv will read the csv into a dataframe, which we can manipulate in R.
raw_df = read.csv(CSV_IN_FILE, stringsAsFactors = TRUE)
head(raw_df)
summary(raw_df)


raw_s_df = read.csv(CSV_S_IN_FILE, stringsAsFactors = TRUE)
head(raw_s_df)
summary(raw_s_df)


```


```{r}
#| label: CreateTarget
#| echo: false
#| message: true
#| warning: false

selected_cols <- c("facility_id", 
               "facility_county",
               "type_of_organization",
               "children_hospital",
               "hospital_ltc",
               "on_site_ltc",
               "privateroomexist",
               "semiprivateroomexist",
               "discharges1864",
               # "dischargestotal",
               "alcohol_drug_detox",
               "alcoholdetox_patient_days",
               "alcoholdetox_beds_lic_vs_staf",
               "alcoholdetox_adm_vs_pat_days",
               "alcohol_drug_treat",
               "alcoholtreat_closing_date",
               "alcoholtreat_beds_lic",
               "alcoholtreat_patient_days",
               "alcoholtreat_beds_lic_vs_staf",
               "alcohol_drug_treat_adm_vs_pat_days",
               "comprehensive_rehab",
               "comprehensive_rehab_beds_lic",
               "Comprehensive_rehab_patient_days",
               "comprehensive_rehab_beds_lic_vs_staf",
               "psych_0to17",
               "psych_0to17_beds_lic",
               "psych_0to17_patient_days",
               "psych_0to17_beds_lic_vs_staf",
               "psych_over17",
               "psych_over17_beds_lic",
               "psych_over17_patient_days",
               "psych_over17_beds_lic_vs_staf",
               "detox",
               "clinpsyc",
               "clinic_psychiatric",
               "psychiatrists"# ,
               # "ft_staff"
               )
FOI <- c( "children_hospital",  #Features of interest
  "psych_over17",
  "discharges1864",
   "psych_over17_beds_lic",
   "psychiatrists",
   "clinic_psychiatric",
   "comprehensive_rehab",
  "type_of_organization"
  )
model_feature_input <- as.formula(paste("target ~", paste(FOI, collapse = " + ")))

# Keep only columns related to model 
## Only select columns that actually exist in the raw data
selected_cols <- selected_cols[!selected_cols %in% setdiff(selected_cols, names(raw_df)) ]
df <- subset(raw_df, select = selected_cols )

#
## Combine with county level suicide data
#
df <- merge(df, raw_s_df, by.x = "facility_county", by.y = "CountyState")
df_merged <- df ## Save state


# Only Keep relevant columns for predicting county suicide rate 
## Only select columns that actually exist in the raw data
selected_cols <- selected_cols[!selected_cols %in% c("facility_county", "CountyState")]
selected_cols <- c(selected_cols,"Obs_Count")
selected_cols <- selected_cols[!selected_cols %in% setdiff(selected_cols, names(df)) ]
df <- subset(df, select = selected_cols )


####
#
# Clean Up Values
#
####
df <- df %>% rename(target = Obs_Count)

Cols2Numeric <- c(
  "target"
)
# Remove formatting from character strings like commas or currency symbols
df <- df %>%
  mutate(across(.cols = all_of(Cols2Numeric), 
    ~ as.numeric(gsub("[^0-9.]", "", as.character(.)))))
df <- df %>%
  mutate(across(.cols = all_of(Cols2Numeric),
    ~ as.numeric(.)
  ))


## Convert Columns with Yes/No values to 0/1 Values
YesNo2Numeric <- df_merged %>%
   select(where(~ any(str_detect(as.character(.), regex("yes", ignore_case = TRUE)), na.rm = TRUE))) %>%
   names()

df <- df %>%
  mutate(across(.cols = all_of(YesNo2Numeric),
    ~ as.numeric(factor(.,
      levels = c("No", "Yes"))) - 1
  ))

## Convert other columns with strings to numbers
Cols2Factors <- c(
  "type_of_organization",
  "clinic_psychiatric"
)
# Convert character strings to Factors to Ints
df$type_of_organization <- as.integer(factor(df_merged$type_of_organization))


# Unique number already the initial character for clinic_psychiatric col
df <- df %>%
  mutate(clinic_psychiatric = str_sub(clinic_psychiatric, 1, 1))
df$clinic_psychiatric <- as.integer(factor(df_merged$clinic_psychiatric))  

df_clean <- df

```

### Data Review

Numeric variables are continuous.

Integer variables are categorical.

```{r}
#| label: ReviewData
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 10

##
## Variable TYPES
##

sapply(df, class)

##
## Visualize target values 
##

# Histogram of target values
target_density <- density(df$target)

# Convert the density estimate to a function
dens_func <- approxfun(target_density$x, target_density$y)

# Use optimize() to find the minimum in a specified interval (choose based on your data)
result <- optimize(dens_func, interval = c(min(df$target), max(df$target)))
local_min_x <- result$minimum     # The x value where local minimum occurs
local_min_y <- result$objective   # The minimum density value

#  Create density plot with ggplot2 and add vertical line at minimum
df_density <- data.frame(x = df$target)
ggplot(df_density, aes(x = df$target)) +
  geom_density(fill = "lightblue", color = "blue", alpha = 0.5) +
  geom_vline(xintercept = local_min_x , color = "red", linetype = "dashed", size = 1) +
  annotate("text", x = local_min_x, y = local_min_y + 0.002, 
    label = sprintf("Min: %.0f", local_min_x), color = "red", angle = 90, vjust = -1, size = 6) +
  labs(title = "Density plot of County Observed Suicide rates in PA", x = "County Suicide Rate per 100,000", y = "Density") +
  coord_cartesian(ylim = c(0, 0.01)) 


## Make TARGET binary for logistic regression
target_bin_cutoff <- local_min_x 

```

Set the cut-off value for 1 or 0 (binary) for Logistic regression is the local minimum of county Suicide Rates.



## Split Dataset into Training and Test

We will leave 80% of observations in the training set and 20% in the test set.

```{r}
#| label: SplitTrainTest
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

#set.seed keeps results random but constant for all using the same seed (so we all will have the same results)
set.seed(1760, sample.kind = "Rejection")
spl = sample(nrow(df),0.8*nrow(df))
head(spl)


# Split into train and test:
train.df = df[spl,]
test.df = df[-spl,]

dim(df)
dim(train.df)
dim(test.df)
```


## Preliminary Analysis

Evaluate Correlation Matrix

```{r}
#| label: CorrelationMatrix
#| echo: true
#| message: true
#| warning: false
#| fig-width: 8
#| fig-height: 10

## Prep for correlation
df_cor <- df_clean

cor_mat <- cor(df)
cor_threshold <- 0
cor_threshold_count <- 2

cols_above_threshold <- which( colSums(abs(cor_mat) > cor_threshold, na.rm = TRUE) >= cor_threshold_count)
df <- subset(df, select = colnames(cor_mat)[cols_above_threshold] )
cor_mat <- cor(df)


cor_mat_plot <- round(cor_mat, 2)
cor_mat_plot[is.na(cor_mat_plot)] <- 0 # Replace all NA values with zero
cat(paste(colnames(cor_mat_plot), collapse = "\n"))


corrplot(cor_mat_plot, 
  method="square",
  type="upper",
  order="AOE", 
  tl.col="darkgrey",
  cl.align.text = "r",
  diag=FALSE, 
  number.cex=0.6)


```


# Regression
## Stepwise Linear Regression

```{r}
#| label: StepwiseRegression
#| warning: false
#| echo: true
#| message: true

model <- lm(target ~ ., data = df)
summary(model)

# Perform stepwise regression
step_model_back <- step(model, direction = "backward",trace=0)
summary(step_model_back)

step_model_forward <- step(model, direction = "forward",trace=0)
summary(step_model_forward)


```



## Logistic Regression

```{r}
#| label: LogisticRegression
#| warning: false
#| echo: true
#| message: true

df <- df_clean
# Update target to be binomial
df$target <- ifelse(df$target < target_bin_cutoff, 0, 1)
train.df = df[spl,]
test.df = df[-spl,]


# Logistic Regression with FOI
logreg <- glm(model_feature_input, data=df, family="binomial")
summary(logreg)


coeftable <- data.frame(col1=coef(logreg),col2=exp(coef(logreg)))
colnames(coeftable)<-c('Coefficient (log-odds)','e^coefficient (odds)')
coeftable

#
# Confusion Matrix
#
df$PredLogOdds <- df$PredProbs <- predict(logreg, newdata=df)
df$PredProbs <- predict(logreg, newdata=df, type="response")  
# type="response" gives the probability
summary(df$PredProbs)


```



# Trees: Regression

```{r}
#| label: TreeRegression1
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

df <- df_clean
train.df = df[spl,]
test.df = df[-spl,]


rpart(model_feature_input, data=train.df)
(train.df%>%filter(children_hospital==1))$target%>%mean()
(train.df%>%filter(children_hospital==0))$target%>%mean()

prp(rpart(target ~ .,data=df, method="anova",minbucket=5,cp=0.0001),digits=-5)
```

## Cross Validation
```{r}
#| label: TreeRegression-CrossValidate
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

set.seed(1760, sample.kind = "Rejection")

tree_cv_all <- rpart(target ~ ., data=train.df, method="anova")
rpart.plot(tree_cv_all, digits=-2, extra=101)
plotcp(tree_cv_all)

tree_cv_foi <- rpart(model_feature_input,data=train.df, method="anova")
rpart.plot(tree_cv_foi, digits=-2, extra=101)
plotcp(tree_cv_foi)


mean_train = mean(train.df$target)
SST = sum((test.df$target - mean_train)^2)

## Predictions
test.df$pred_cv_all = predict(tree_cv_all, newdata=test.df)
test.df$pred_cv_foi = predict(tree_cv_foi, newdata=test.df) 
 
# Compute the sum of squared errors (SSE) using our tree:
SSE_all = sum((test.df$target - test.df$pred_cv_all)^2)
print(paste("Tree All has a SSE of", SSE_all))
OSR2_all = 1 - SSE_all/SST
OSR2_all


# Compute the sum of squared errors (SSE) using our tree:
SSE_foi = sum((test.df$target - test.df$pred_cv_foi)^2)
print(paste("Tree FOI has a SSE of", SSE_foi))
OSR2_foi = 1 - SSE_foi/SST
OSR2_foi

```


Let's see the MAE for comparisons:
```{r}
#| label: TreeRegression-CompareModelMAE
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

MAE = mean(abs(test.df$target - test.df$pred01))

MAE

```





# Trees: Classification

```{r}
#| label: TreeClassification
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

df <- df_clean
# Update target to be binomial
df$target <- ifelse(df$target < target_bin_cutoff, 0, 1)
train.df = df[spl,]
test.df = df[-spl,] 


#It is always a good practice to see the proportion of observations we have for each case
table(df$target)
prop.table(table(df$target))  # prop is "proportion"


cat("\n For the train dataset: ")      #  \n is a "new line" printing control
prop.table(table(train.df$target))
cat("\n For the test dataset: ")
prop.table(table(test.df$target))


tree_all <-rpart(target ~ ., data=train.df, method="class",cp=0.05)
rpart.plot(tree_all, digits=-2)
prp(tree_all)

tree_foi<-rpart(model_feature_input, data=train.df, method="class", cp=0.05)
rpart.plot(tree_foi,digits=-2)
prp(tree_foi)

```


## Cross-Validation
```{r}
#| label: TreeClassification-CrossValidation
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10


cat("All Features Tree:")
test.df$pred_all = predict(tree_all, newdata = test.df, type="class")
confusionMatrix(test.df$pred_all,as.factor(test.df$target), positive="1")
acc_tree_all <- sum(test.df$pred_all == test.df$target) / nrow(test.df)
print(paste("Accuracy for All Features Tree", round(acc_tree_all * 100, 2), "%"))


cat("FOI Tree:")
test.df$pred_foi = predict(tree_foi, newdata = test.df, type="class")
confusionMatrix(test.df$pred_foi,as.factor(test.df$target), positive="1")
acc_tree_foi <- sum(test.df$pred_foi == test.df$target) / nrow(test.df)
print(paste("Accuracy for FOI Tree:", round(acc_tree_foi * 100, 2), "%"))

```



## Compare Classification Tree with Logistic regressions

```{r}
#| label: TreeClassificationVSLogisticRegression1
#| echo: true
#| message: true
#| warning: false
#| fig-width: 10
#| fig-height: 10

## Logistic Regression
test.df$predregprobs_foi = predict(logreg, newdata = test.df, type="response")
test.df$predreg1<-ifelse(test.df$predregprobs_foi>0.5,1,0)
acc_reg <- sum(test.df$predregprobs_foi == test.df$target) / nrow(test.df)
print(paste("Accuracy for Logistic Regression 1:", round(acc_reg * 100, 2), "%"))
ConfMatReg <- confusionMatrix(data=as.factor(test.df$predreg1),reference=as.factor(test.df$target), positive = "1")
ConfMatReg 

# Classification Tree
test.df$predregtreeprobs_foi = predict(tree_foi, newdata = test.df, type="class")
test.df$predreg2 <- ifelse(test.df$predregtreeprobs_foi >0.5 ,1 ,0)
acc_reg_tree <- sum(test.df$predregtreeprobs_foi == test.df$target) / nrow(test.df)
print(paste("Accuracy for Classification Tree:", round(acc_reg_tree * 100, 2), "%"))
ConfMatTreeReg <-confusionMatrix(data=as.factor(test.df$predregtreeprobs_foi),reference=as.factor(test.df$target), positive = "1")
ConfMatTreeReg

```






# References

Hospital Data: https://www.pa.gov/psych_over17ncies/health/health-statistics/health-facilities/hospital-reports

Suicide by County Data: https://www.phaim.health.pa.gov/EDD/WebForms/DeathCntySt.aspx
